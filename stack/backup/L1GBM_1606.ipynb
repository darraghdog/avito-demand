{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "import sys\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "path = \"/home/darragh/avito/data/\"\n",
    "#path = '/Users/dhanley2/Documents/avito/data/'\n",
    "#path = '/home/ubuntu/avito/data/'\n",
    "#data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnames = ['item_id', 'deal_probability']\n",
    "#rnn27 = pd.concat([pd.read_csv(path+'../sub/rnndhCV_1206B_trn.csv', header = None, names = cnames), \n",
    "#                   pd.read_csv(path+'../sub/rnndhCV_1206A_tst.csv', header = None, names = cnames)])\n",
    "#rnn27.to_csv(path+'../sub/rnnCV_1206.csv.gz', compression='gzip', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb25 = pd.read_csv('../lgCV_2505.csv.gz', compression='gzip')\n",
    "lgb02A = pd.read_csv(path+'../sub/lgCV_0206A.csv.gz', compression='gzip')\n",
    "lgb09 = pd.read_csv(path+'../sub/lgCV_0906.csv.gz', compression='gzip')\n",
    "lgb10 = pd.read_csv(path+'../sub/lgCV_1006.csv.gz', compression='gzip')\n",
    "lgb11A= pd.read_csv(path+'../sub/lgCV_1106A.csv.gz', compression='gzip')\n",
    "lgb11D= pd.read_csv(path+'../sub/lgCV_1106D.csv.gz', compression='gzip')\n",
    "lgb14= pd.read_csv(path+'../sub/lgCV_1406.csv.gz', compression='gzip')\n",
    "lgb14A= pd.read_csv(path+'../sub/lgCV_1406A.csv.gz', compression='gzip')\n",
    "lgb27 = pd.read_csv(path+'../sub/lgCV_2705B.csv.gz', compression='gzip')\n",
    "lgb31 = pd.read_csv(path+'../sub/lgCV_3105.csv.gz', compression='gzip')\n",
    "lgb02 = pd.read_csv(path+'../sub/lgCV_0206.csv.gz', compression='gzip')\n",
    "rnn =   pd.read_csv(path+'../sub/rnnCV_2805.csv.gz', compression='gzip')\n",
    "rnn27 = pd.read_csv(path+'../sub/rnnCV_2705A.csv.gz', compression='gzip')\n",
    "rnn12 = pd.read_csv(path+'../sub/rnnCV_1206.csv.gz', compression='gzip')\n",
    "mlp =   pd.read_csv(path+'../sub/mlpCV_2505.csv.gz', compression='gzip')\n",
    "truth = pd.read_csv(path+'train.csv.zip', compression='zip', parse_dates = [\"activation_date\"])\n",
    "y =     truth['deal_probability'].values\n",
    "truth.drop('deal_probability', 1)\n",
    "test =  pd.read_csv(path+'test.csv.zip', compression='zip', parse_dates = [\"activation_date\"])\n",
    "test['deal_probability']=float('NAN') \n",
    "truth = pd.concat([truth,test[truth.columns]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb14['deal_probability'] =  ( lgb14['deal_probability'].values + lgb14A['deal_probability'].values)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb25.rename(columns={'deal_probability': 'lgb25_preds' }, inplace=True)\n",
    "lgb31.rename(columns={'deal_probability': 'lgb31_preds' }, inplace=True)\n",
    "lgb27.rename(columns={'deal_probability': 'lgb27_preds' }, inplace=True)\n",
    "lgb02.rename(columns={'deal_probability': 'lgb02_preds' }, inplace=True)\n",
    "lgb09.rename(columns={'deal_probability': 'lgb09_preds' }, inplace=True)\n",
    "lgb10.rename(columns={'deal_probability': 'lgb10_preds' }, inplace=True)\n",
    "lgb11D.rename(columns={'deal_probability': 'lgb11D_preds' }, inplace=True)\n",
    "lgb11A.rename(columns={'deal_probability': 'lgb11A_preds' }, inplace=True)\n",
    "lgb14.rename(columns={'deal_probability': 'lgb14_preds' }, inplace=True)\n",
    "lgb02A.rename(columns={'deal_probability': 'lgb02A_preds' }, inplace=True)\n",
    "rnn27.rename(columns={'deal_probability': 'rnn27_preds' }, inplace=True)\n",
    "rnn12.rename(columns={'deal_probability': 'rnn12_preds' }, inplace=True)\n",
    "mlp.rename(columns={'deal_probability': 'mlp_preds' }, inplace=True)\n",
    "preds_df = lgb27.merge(rnn, on='item_id')\\\n",
    "                .merge(mlp, on='item_id')\\\n",
    "                .merge(lgb31, on='item_id')\\\n",
    "                .merge(lgb02, on='item_id')\\\n",
    "                .merge(lgb09, on='item_id')\\\n",
    "                .merge(lgb10, on='item_id')\\\n",
    "                .merge(lgb11A, on='item_id')\\\n",
    "                .merge(lgb11D, on='item_id')\\\n",
    "                .merge(lgb14, on='item_id')\\\n",
    "                .merge(lgb02A, on='item_id')\\\n",
    "                .merge(rnn27, on='item_id')\\\n",
    "                .merge(rnn12, on='item_id')\\\n",
    "                .merge(truth, on='item_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rnn_preds',\n",
       " 'mlp_preds',\n",
       " 'lgb31_preds',\n",
       " 'lgb09_preds',\n",
       " 'lgb10_preds',\n",
       " 'lgb11D_preds',\n",
       " 'lgb14_preds',\n",
       " 'lgb02A_preds',\n",
       " 'rnn27_preds',\n",
       " 'rnn12_preds']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [col for col in preds_df.columns if ('_preds' in col) \\\n",
    "             and ('lgb27' not in col) and ('lgb02_' not in col) and ('lgb11A_' not in col)]\n",
    "\n",
    "preds_df['preds_sum'] = preds_df[pred_cols].sum(axis=1)\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df['price'].fillna(-1,inplace=True)\n",
    "preds_df['max'] = np.max(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['min'] = np.min(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['avg'] = np.mean(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['std'] = np.std(np.array([preds_df[col] for col in pred_cols]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference_rnn_preds__mlp_preds\n",
      "difference_rnn_preds__lgb31_preds\n",
      "difference_rnn_preds__lgb09_preds\n",
      "difference_rnn_preds__lgb10_preds\n",
      "difference_rnn_preds__lgb11D_preds\n",
      "difference_rnn_preds__lgb14_preds\n",
      "difference_rnn_preds__lgb02A_preds\n",
      "difference_rnn_preds__rnn27_preds\n",
      "difference_rnn_preds__rnn12_preds\n",
      "difference_mlp_preds__lgb31_preds\n",
      "difference_mlp_preds__lgb09_preds\n",
      "difference_mlp_preds__lgb10_preds\n",
      "difference_mlp_preds__lgb11D_preds\n",
      "difference_mlp_preds__lgb14_preds\n",
      "difference_mlp_preds__lgb02A_preds\n",
      "difference_mlp_preds__rnn27_preds\n",
      "difference_mlp_preds__rnn12_preds\n",
      "difference_lgb31_preds__lgb09_preds\n",
      "difference_lgb31_preds__lgb10_preds\n",
      "difference_lgb31_preds__lgb11D_preds\n",
      "difference_lgb31_preds__lgb14_preds\n",
      "difference_lgb31_preds__lgb02A_preds\n",
      "difference_lgb31_preds__rnn27_preds\n",
      "difference_lgb31_preds__rnn12_preds\n",
      "difference_lgb09_preds__lgb10_preds\n",
      "difference_lgb09_preds__lgb11D_preds\n",
      "difference_lgb09_preds__lgb14_preds\n",
      "difference_lgb09_preds__lgb02A_preds\n",
      "difference_lgb09_preds__rnn27_preds\n",
      "difference_lgb09_preds__rnn12_preds\n",
      "difference_lgb10_preds__lgb11D_preds\n",
      "difference_lgb10_preds__lgb14_preds\n",
      "difference_lgb10_preds__lgb02A_preds\n",
      "difference_lgb10_preds__rnn27_preds\n",
      "difference_lgb10_preds__rnn12_preds\n",
      "difference_lgb11D_preds__lgb14_preds\n",
      "difference_lgb11D_preds__lgb02A_preds\n",
      "difference_lgb11D_preds__rnn27_preds\n",
      "difference_lgb11D_preds__rnn12_preds\n",
      "difference_lgb14_preds__lgb02A_preds\n",
      "difference_lgb14_preds__rnn27_preds\n",
      "difference_lgb14_preds__rnn12_preds\n",
      "difference_lgb02A_preds__rnn27_preds\n",
      "difference_lgb02A_preds__rnn12_preds\n",
      "difference_rnn27_preds__rnn12_preds\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for p1, p2 in itertools.combinations(pred_cols, 2):\n",
    "    print('difference_%s__%s'%(p1,p2))\n",
    "    preds_df['difference_%s__%s'%(p1,p2)] = preds_df[p2] - preds_df[p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>...</th>\n",
       "      <th>difference_lgb11D_preds__lgb14_preds</th>\n",
       "      <th>difference_lgb11D_preds__lgb02A_preds</th>\n",
       "      <th>difference_lgb11D_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb11D_preds__rnn12_preds</th>\n",
       "      <th>difference_lgb14_preds__lgb02A_preds</th>\n",
       "      <th>difference_lgb14_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb14_preds__rnn12_preds</th>\n",
       "      <th>difference_lgb02A_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb02A_preds__rnn12_preds</th>\n",
       "      <th>difference_rnn27_preds__rnn12_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>0.091656</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.091223</td>\n",
       "      <td>0.083219</td>\n",
       "      <td>0.090855</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.092921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008715</td>\n",
       "      <td>0.016697</td>\n",
       "      <td>-0.024590</td>\n",
       "      <td>-0.016043</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>-0.015875</td>\n",
       "      <td>-0.007329</td>\n",
       "      <td>-0.041287</td>\n",
       "      <td>-0.032740</td>\n",
       "      <td>0.008546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>0.147801</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>0.211844</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.119609</td>\n",
       "      <td>0.157466</td>\n",
       "      <td>0.161107</td>\n",
       "      <td>0.140269</td>\n",
       "      <td>0.144395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008224</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.073757</td>\n",
       "      <td>-0.055836</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>-0.065534</td>\n",
       "      <td>-0.047612</td>\n",
       "      <td>-0.089406</td>\n",
       "      <td>-0.071485</td>\n",
       "      <td>0.017921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>0.186261</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>0.236579</td>\n",
       "      <td>0.227048</td>\n",
       "      <td>0.258980</td>\n",
       "      <td>0.245236</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>0.234076</td>\n",
       "      <td>0.222678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023230</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>-0.060754</td>\n",
       "      <td>-0.074653</td>\n",
       "      <td>0.041888</td>\n",
       "      <td>-0.037524</td>\n",
       "      <td>-0.051423</td>\n",
       "      <td>-0.079412</td>\n",
       "      <td>-0.093311</td>\n",
       "      <td>-0.013899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>0.260876</td>\n",
       "      <td>0.383699</td>\n",
       "      <td>0.231447</td>\n",
       "      <td>0.284130</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.255519</td>\n",
       "      <td>0.241802</td>\n",
       "      <td>0.271355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012286</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>-0.023032</td>\n",
       "      <td>0.077387</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>-0.010746</td>\n",
       "      <td>-0.057652</td>\n",
       "      <td>-0.088132</td>\n",
       "      <td>-0.030481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>0.407423</td>\n",
       "      <td>0.431520</td>\n",
       "      <td>0.420657</td>\n",
       "      <td>0.412563</td>\n",
       "      <td>0.430581</td>\n",
       "      <td>0.511145</td>\n",
       "      <td>0.511676</td>\n",
       "      <td>0.504849</td>\n",
       "      <td>0.503961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002923</td>\n",
       "      <td>-0.081972</td>\n",
       "      <td>-0.153677</td>\n",
       "      <td>-0.082617</td>\n",
       "      <td>-0.079049</td>\n",
       "      <td>-0.150753</td>\n",
       "      <td>-0.079694</td>\n",
       "      <td>-0.071704</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.071059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "0  b912c3c6a6ad     0.091656   0.069891   0.091223     0.083219     0.090855   \n",
       "1  2dac0150717d     0.147801   0.075968   0.211844     0.157973     0.119609   \n",
       "2  ba83aefab5dc     0.186261   0.167167   0.236579     0.227048     0.258980   \n",
       "3  02996f1dd2ea     0.241699   0.260876   0.383699     0.231447     0.284130   \n",
       "4  7c90be56d2ab     0.407423   0.431520   0.420657     0.412563     0.430581   \n",
       "\n",
       "   lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "0     0.109624     0.107764      0.095101      0.092921   \n",
       "1     0.157466     0.161107      0.140269      0.144395   \n",
       "2     0.245236     0.219107      0.234076      0.222678   \n",
       "3     0.289101     0.255519      0.241802      0.271355   \n",
       "4     0.511145     0.511676      0.504849      0.503961   \n",
       "\n",
       "                  ...                  difference_lgb11D_preds__lgb14_preds  \\\n",
       "0                 ...                                             -0.008715   \n",
       "1                 ...                                             -0.008224   \n",
       "2                 ...                                             -0.023230   \n",
       "3                 ...                                             -0.012286   \n",
       "4                 ...                                             -0.002923   \n",
       "\n",
       "   difference_lgb11D_preds__lgb02A_preds  \\\n",
       "0                               0.016697   \n",
       "1                               0.015649   \n",
       "2                               0.018658   \n",
       "3                               0.065100   \n",
       "4                              -0.081972   \n",
       "\n",
       "   difference_lgb11D_preds__rnn27_preds  difference_lgb11D_preds__rnn12_preds  \\\n",
       "0                             -0.024590                             -0.016043   \n",
       "1                             -0.073757                             -0.055836   \n",
       "2                             -0.060754                             -0.074653   \n",
       "3                              0.007448                             -0.023032   \n",
       "4                             -0.153677                             -0.082617   \n",
       "\n",
       "   difference_lgb14_preds__lgb02A_preds difference_lgb14_preds__rnn27_preds  \\\n",
       "0                              0.025412                           -0.015875   \n",
       "1                              0.023873                           -0.065534   \n",
       "2                              0.041888                           -0.037524   \n",
       "3                              0.077387                            0.019735   \n",
       "4                             -0.079049                           -0.150753   \n",
       "\n",
       "  difference_lgb14_preds__rnn12_preds difference_lgb02A_preds__rnn27_preds  \\\n",
       "0                           -0.007329                            -0.041287   \n",
       "1                           -0.047612                            -0.089406   \n",
       "2                           -0.051423                            -0.079412   \n",
       "3                           -0.010746                            -0.057652   \n",
       "4                           -0.079694                            -0.071704   \n",
       "\n",
       "  difference_lgb02A_preds__rnn12_preds difference_rnn27_preds__rnn12_preds  \n",
       "0                            -0.032740                            0.008546  \n",
       "1                            -0.071485                            0.017921  \n",
       "2                            -0.093311                           -0.013899  \n",
       "3                            -0.088132                           -0.030481  \n",
       "4                            -0.000645                            0.071059  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb27_preds',\n",
       " 'rnn_preds',\n",
       " 'mlp_preds',\n",
       " 'lgb31_preds',\n",
       " 'lgb02_preds',\n",
       " 'lgb09_preds',\n",
       " 'lgb10_preds',\n",
       " 'lgb11A_preds',\n",
       " 'lgb11D_preds',\n",
       " 'lgb14_preds',\n",
       " 'lgb02A_preds',\n",
       " 'rnn27_preds',\n",
       " 'rnn12_preds',\n",
       " 'preds_sum']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [col for col in preds_df.columns if ('preds' in col) and ('difference' not in col)]\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1503424\n",
      "False     508438\n",
      "Name: deal_probability, dtype: int64\n",
      "RMSE lgb27_preds:  0.21681527582821059\n",
      "RMSE rnn_preds:  0.21771476573780568\n",
      "RMSE mlp_preds:  0.2187544351068867\n",
      "RMSE lgb31_preds:  0.21681135578306754\n",
      "RMSE lgb02_preds:  0.21625386267187377\n",
      "RMSE lgb09_preds:  0.21581543265040168\n",
      "RMSE lgb10_preds:  0.21533498019117664\n",
      "RMSE lgb11A_preds:  0.21403812331071156\n",
      "RMSE lgb11D_preds:  0.21392147604708842\n",
      "RMSE lgb14_preds:  0.21329729304260686\n",
      "RMSE lgb02A_preds:  0.21627136604335995\n",
      "RMSE rnn27_preds:  0.21698040871120608\n",
      "RMSE rnn12_preds:  0.2167114508342396\n"
     ]
    }
   ],
   "source": [
    "idx = preds_df['deal_probability']==preds_df['deal_probability']\n",
    "print(idx.value_counts())\n",
    "for col in [c for c in preds_df.columns if ('_preds' in c)  and ('difference' not in c) ]:\n",
    "    print('RMSE %s: '%(col), np.sqrt(metrics.mean_squared_error(preds_df['deal_probability'][idx].values, preds_df[col][idx].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldls = [[\"2017-03-15\", \"2017-03-16\", \"2017-03-17\"], \\\n",
    "       [\"2017-03-18\", \"2017-03-19\", \"2017-03-20\"], \\\n",
    "       [\"2017-03-21\", \"2017-03-22\", \"2017-03-23\"], \\\n",
    "       [\"2017-03-24\", \"2017-03-25\", \"2017-03-26\"], \\\n",
    "        [\"2017-03-27\", \"2017-03-28\", \"2017-03-29\", \\\n",
    "            \"2017-03-30\", \"2017-03-31\", \"2017-04-01\", \\\n",
    "            \"2017-04-02\", \"2017-04-03\",\"2017-04-07\"]]\n",
    "foldls = [[pd.to_datetime(d) for d in f] for f in foldls]\n",
    "preds_df['fold'] = -1\n",
    "for t, fold in enumerate(foldls):\n",
    "    preds_df['fold'][preds_df.activation_date.isin(fold)] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold0</th>\n",
       "      <th>Fold1</th>\n",
       "      <th>Fold2</th>\n",
       "      <th>Fold3</th>\n",
       "      <th>Fold4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgb27_preds</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.217096</td>\n",
       "      <td>0.217923</td>\n",
       "      <td>0.217597</td>\n",
       "      <td>0.213692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnn_preds</td>\n",
       "      <td>0.218756</td>\n",
       "      <td>0.218966</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.219554</td>\n",
       "      <td>0.214747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp_preds</td>\n",
       "      <td>0.219660</td>\n",
       "      <td>0.220088</td>\n",
       "      <td>0.216672</td>\n",
       "      <td>0.220347</td>\n",
       "      <td>0.216385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb31_preds</td>\n",
       "      <td>0.216537</td>\n",
       "      <td>0.216643</td>\n",
       "      <td>0.219230</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.213430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgb02_preds</td>\n",
       "      <td>0.216371</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.217354</td>\n",
       "      <td>0.217032</td>\n",
       "      <td>0.213158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb09_preds</td>\n",
       "      <td>0.215514</td>\n",
       "      <td>0.215678</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>0.216073</td>\n",
       "      <td>0.212293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb10_preds</td>\n",
       "      <td>0.215240</td>\n",
       "      <td>0.215533</td>\n",
       "      <td>0.217072</td>\n",
       "      <td>0.215802</td>\n",
       "      <td>0.212023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgb11A_preds</td>\n",
       "      <td>0.215011</td>\n",
       "      <td>0.215205</td>\n",
       "      <td>0.211879</td>\n",
       "      <td>0.215771</td>\n",
       "      <td>0.211735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgb11D_preds</td>\n",
       "      <td>0.214818</td>\n",
       "      <td>0.215074</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.211549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lgb14_preds</td>\n",
       "      <td>0.214204</td>\n",
       "      <td>0.214441</td>\n",
       "      <td>0.211074</td>\n",
       "      <td>0.215146</td>\n",
       "      <td>0.211051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgb02A_preds</td>\n",
       "      <td>0.216081</td>\n",
       "      <td>0.216051</td>\n",
       "      <td>0.218825</td>\n",
       "      <td>0.216562</td>\n",
       "      <td>0.212741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rnn27_preds</td>\n",
       "      <td>0.218097</td>\n",
       "      <td>0.218115</td>\n",
       "      <td>0.214982</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.214379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rnn12_preds</td>\n",
       "      <td>0.217658</td>\n",
       "      <td>0.217913</td>\n",
       "      <td>0.214952</td>\n",
       "      <td>0.218472</td>\n",
       "      <td>0.213781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model     Fold0     Fold1     Fold2     Fold3     Fold4\n",
       "0    lgb27_preds  0.216848  0.217096  0.217923  0.217597  0.213692\n",
       "1      rnn_preds  0.218756  0.218966  0.215764  0.219554  0.214747\n",
       "2      mlp_preds  0.219660  0.220088  0.216672  0.220347  0.216385\n",
       "3    lgb31_preds  0.216537  0.216643  0.219230  0.217169  0.213430\n",
       "4    lgb02_preds  0.216371  0.216447  0.217354  0.217032  0.213158\n",
       "5    lgb09_preds  0.215514  0.215678  0.218418  0.216073  0.212293\n",
       "6    lgb10_preds  0.215240  0.215533  0.217072  0.215802  0.212023\n",
       "7   lgb11A_preds  0.215011  0.215205  0.211879  0.215771  0.211735\n",
       "8   lgb11D_preds  0.214818  0.215074  0.211837  0.215720  0.211549\n",
       "9    lgb14_preds  0.214204  0.214441  0.211074  0.215146  0.211051\n",
       "10  lgb02A_preds  0.216081  0.216051  0.218825  0.216562  0.212741\n",
       "11   rnn27_preds  0.218097  0.218115  0.214982  0.218651  0.214379\n",
       "12   rnn12_preds  0.217658  0.217913  0.214952  0.218472  0.213781"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for col in [c for c in preds_df.columns if ('_preds' in c)  and ('difference' not in c) ]:\n",
    "    lstmp = [col]\n",
    "    for i in range(5):\n",
    "        idx = preds_df['fold']==i\n",
    "        lstmp.append(np.sqrt(metrics.mean_squared_error(preds_df['deal_probability'][idx].values, \\\n",
    "                                                        preds_df[col][idx].values)))\n",
    "    scores.append(lstmp)\n",
    "pd.DataFrame(scores, columns = ['Model']+['Fold%s'%(i) for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>lgb14_preds</th>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <th>rnn27_preds</th>\n",
       "      <th>rnn12_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgb27_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.919171</td>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.978298</td>\n",
       "      <td>0.966819</td>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.961540</td>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.916804</td>\n",
       "      <td>0.920576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_preds</th>\n",
       "      <td>0.915952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929710</td>\n",
       "      <td>0.910602</td>\n",
       "      <td>0.913307</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.912870</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.985360</td>\n",
       "      <td>0.978274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_preds</th>\n",
       "      <td>0.919171</td>\n",
       "      <td>0.929710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>0.916343</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.929518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb31_preds</th>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.910602</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991984</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.981375</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.914204</td>\n",
       "      <td>0.916939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02_preds</th>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.913307</td>\n",
       "      <td>0.916343</td>\n",
       "      <td>0.991984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>0.982052</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.916726</td>\n",
       "      <td>0.920105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb09_preds</th>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990447</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>0.912375</td>\n",
       "      <td>0.915090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb10_preds</th>\n",
       "      <td>0.978298</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>0.981375</td>\n",
       "      <td>0.982052</td>\n",
       "      <td>0.990447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.920034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <td>0.966819</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.988703</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.923137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.917196</td>\n",
       "      <td>0.921322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb14_preds</th>\n",
       "      <td>0.961540</td>\n",
       "      <td>0.912870</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.988703</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>0.916160</td>\n",
       "      <td>0.920547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>0.917453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn27_preds</th>\n",
       "      <td>0.916804</td>\n",
       "      <td>0.985360</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.914204</td>\n",
       "      <td>0.916726</td>\n",
       "      <td>0.912375</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.917196</td>\n",
       "      <td>0.916160</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn12_preds</th>\n",
       "      <td>0.920576</td>\n",
       "      <td>0.978274</td>\n",
       "      <td>0.929518</td>\n",
       "      <td>0.916939</td>\n",
       "      <td>0.920105</td>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.920034</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.921322</td>\n",
       "      <td>0.920547</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>0.979744</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "lgb27_preds      1.000000   0.915952   0.919171     0.990750     0.988682   \n",
       "rnn_preds        0.915952   1.000000   0.929710     0.910602     0.913307   \n",
       "mlp_preds        0.919171   0.929710   1.000000     0.914307     0.916343   \n",
       "lgb31_preds      0.990750   0.910602   0.914307     1.000000     0.991984   \n",
       "lgb02_preds      0.988682   0.913307   0.916343     0.991984     1.000000   \n",
       "lgb09_preds      0.978331   0.908867   0.909521     0.981891     0.982596   \n",
       "lgb10_preds      0.978298   0.913286   0.913883     0.981375     0.982052   \n",
       "lgb11A_preds     0.966819   0.915655   0.915367     0.966656     0.970858   \n",
       "lgb11D_preds     0.965873   0.913936   0.913018     0.965897     0.969933   \n",
       "lgb14_preds      0.961540   0.912870   0.911656     0.961575     0.966325   \n",
       "lgb02A_preds     0.983143   0.911443   0.913600     0.986851     0.987434   \n",
       "rnn27_preds      0.916804   0.985360   0.925010     0.914204     0.916726   \n",
       "rnn12_preds      0.920576   0.978274   0.929518     0.916939     0.920105   \n",
       "\n",
       "              lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "lgb27_preds      0.978331     0.978298      0.966819      0.965873   \n",
       "rnn_preds        0.908867     0.913286      0.915655      0.913936   \n",
       "mlp_preds        0.909521     0.913883      0.915367      0.913018   \n",
       "lgb31_preds      0.981891     0.981375      0.966656      0.965897   \n",
       "lgb02_preds      0.982596     0.982052      0.970858      0.969933   \n",
       "lgb09_preds      1.000000     0.990447      0.976755      0.976540   \n",
       "lgb10_preds      0.990447     1.000000      0.982841      0.982033   \n",
       "lgb11A_preds     0.976755     0.982841      1.000000      0.992400   \n",
       "lgb11D_preds     0.976540     0.982033      0.992400      1.000000   \n",
       "lgb14_preds      0.972392     0.977396      0.988703      0.989978   \n",
       "lgb02A_preds     0.988708     0.985858      0.971893      0.971846   \n",
       "rnn27_preds      0.912375     0.916436      0.918727      0.917196   \n",
       "rnn12_preds      0.915090     0.920034      0.923137      0.921322   \n",
       "\n",
       "              lgb14_preds  lgb02A_preds  rnn27_preds  rnn12_preds  \n",
       "lgb27_preds      0.961540      0.983143     0.916804     0.920576  \n",
       "rnn_preds        0.912870      0.911443     0.985360     0.978274  \n",
       "mlp_preds        0.911656      0.913600     0.925010     0.929518  \n",
       "lgb31_preds      0.961575      0.986851     0.914204     0.916939  \n",
       "lgb02_preds      0.966325      0.987434     0.916726     0.920105  \n",
       "lgb09_preds      0.972392      0.988708     0.912375     0.915090  \n",
       "lgb10_preds      0.977396      0.985858     0.916436     0.920034  \n",
       "lgb11A_preds     0.988703      0.971893     0.918727     0.923137  \n",
       "lgb11D_preds     0.989978      0.971846     0.917196     0.921322  \n",
       "lgb14_preds      1.000000      0.967560     0.916160     0.920547  \n",
       "lgb02A_preds     0.967560      1.000000     0.914911     0.917453  \n",
       "rnn27_preds      0.916160      0.914911     1.000000     0.979744  \n",
       "rnn12_preds      0.920547      0.917453     0.979744     1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test correlation\n",
    "preds_df[~preds_df['deal_probability'].isnull()][[c for c in preds_df.columns if ('_preds' in c)  and ('difference' not in c) ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>lgb14_preds</th>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <th>rnn27_preds</th>\n",
       "      <th>rnn12_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgb27_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930288</td>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.979341</td>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.970062</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.932951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_preds</th>\n",
       "      <td>0.930288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.984113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_preds</th>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.920496</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.916323</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.935069</td>\n",
       "      <td>0.936609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb31_preds</th>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.982519</td>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.932981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02_preds</th>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>0.983525</td>\n",
       "      <td>0.980105</td>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.931447</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb09_preds</th>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>0.983504</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.929748</td>\n",
       "      <td>0.931167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb10_preds</th>\n",
       "      <td>0.979341</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.920496</td>\n",
       "      <td>0.982519</td>\n",
       "      <td>0.983525</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.933902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.980105</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>0.990047</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.930518</td>\n",
       "      <td>0.932743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.931133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb14_preds</th>\n",
       "      <td>0.970062</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>0.916323</td>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.983504</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.990047</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>0.928224</td>\n",
       "      <td>0.930421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>0.933267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn27_preds</th>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.935069</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.931447</td>\n",
       "      <td>0.929748</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.930518</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.928224</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn12_preds</th>\n",
       "      <td>0.932951</td>\n",
       "      <td>0.984113</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.931167</td>\n",
       "      <td>0.933902</td>\n",
       "      <td>0.932743</td>\n",
       "      <td>0.931133</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "lgb27_preds      1.000000   0.930288   0.924283     0.991439     0.989502   \n",
       "rnn_preds        0.930288   1.000000   0.939951     0.927835     0.927867   \n",
       "mlp_preds        0.924283   0.939951   1.000000     0.922413     0.921927   \n",
       "lgb31_preds      0.991439   0.927835   0.922413     1.000000     0.993168   \n",
       "lgb02_preds      0.989502   0.927867   0.921927     0.993168     1.000000   \n",
       "lgb09_preds      0.979729   0.926158   0.918064     0.982874     0.984427   \n",
       "lgb10_preds      0.979341   0.928367   0.920496     0.982519     0.983525   \n",
       "lgb11A_preds     0.975840   0.927119   0.919275     0.978877     0.980105   \n",
       "lgb11D_preds     0.973725   0.925632   0.917496     0.976777     0.978173   \n",
       "lgb14_preds      0.970062   0.924680   0.916323     0.973170     0.975031   \n",
       "lgb02A_preds     0.984742   0.928496   0.922121     0.988043     0.989577   \n",
       "rnn27_preds      0.930692   0.988198   0.935069     0.931468     0.931447   \n",
       "rnn12_preds      0.932951   0.984113   0.936609     0.932981     0.933333   \n",
       "\n",
       "              lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "lgb27_preds      0.979729     0.979341      0.975840      0.973725   \n",
       "rnn_preds        0.926158     0.928367      0.927119      0.925632   \n",
       "mlp_preds        0.918064     0.920496      0.919275      0.917496   \n",
       "lgb31_preds      0.982874     0.982519      0.978877      0.976777   \n",
       "lgb02_preds      0.984427     0.983525      0.980105      0.978173   \n",
       "lgb09_preds      1.000000     0.991413      0.988267      0.986666   \n",
       "lgb10_preds      0.991413     1.000000      0.992340      0.990473   \n",
       "lgb11A_preds     0.988267     0.992340      1.000000      0.993474   \n",
       "lgb11D_preds     0.986666     0.990473      0.993474      1.000000   \n",
       "lgb14_preds      0.983504     0.986869      0.990047      0.991525   \n",
       "lgb02A_preds     0.989106     0.986654      0.983556      0.981933   \n",
       "rnn27_preds      0.929748     0.931841      0.930518      0.929068   \n",
       "rnn12_preds      0.931167     0.933902      0.932743      0.931133   \n",
       "\n",
       "              lgb14_preds  lgb02A_preds  rnn27_preds  rnn12_preds  \n",
       "lgb27_preds      0.970062      0.984742     0.930692     0.932951  \n",
       "rnn_preds        0.924680      0.928496     0.988198     0.984113  \n",
       "mlp_preds        0.916323      0.922121     0.935069     0.936609  \n",
       "lgb31_preds      0.973170      0.988043     0.931468     0.932981  \n",
       "lgb02_preds      0.975031      0.989577     0.931447     0.933333  \n",
       "lgb09_preds      0.983504      0.989106     0.929748     0.931167  \n",
       "lgb10_preds      0.986869      0.986654     0.931841     0.933902  \n",
       "lgb11A_preds     0.990047      0.983556     0.930518     0.932743  \n",
       "lgb11D_preds     0.991525      0.981933     0.929068     0.931133  \n",
       "lgb14_preds      1.000000      0.978724     0.928224     0.930421  \n",
       "lgb02A_preds     0.978724      1.000000     0.932071     0.933267  \n",
       "rnn27_preds      0.928224      0.932071     1.000000     0.987051  \n",
       "rnn12_preds      0.930421      0.933267     0.987051     1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train correlation\n",
    "preds_df[preds_df['deal_probability'].isnull()][[c for c in preds_df.columns if ('_preds' in c)  and ('difference' not in c) ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in preds_df.columns if '_preds' in c]\n",
    "cols += [c for c in preds_df.columns if 'difference' in c]\n",
    "cols += ['price', 'max', 'min', 'avg', 'std']\n",
    "categories = ['region', 'param_1', 'parent_category_name', 'category_name', 'param_2' ]\n",
    "cols += categories\n",
    "cols = list(set(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categories:\n",
    "    preds_df[col] = LabelEncoder().fit_transform(preds_df[col].fillna(\"0\"))\n",
    "train_df = preds_df[~preds_df['deal_probability'].isnull()]\n",
    "test_df = preds_df[preds_df['deal_probability'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 4000\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_df[cols], y, train_size=.8, random_state=12345)\n",
    "eval_set = [(train_X,train_y),(valid_X,valid_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202739"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219409\tvalid_1's rmse: 0.219809\n",
      "[200]\ttraining's rmse: 0.212874\tvalid_1's rmse: 0.213563\n",
      "[300]\ttraining's rmse: 0.211679\tvalid_1's rmse: 0.212604\n",
      "[400]\ttraining's rmse: 0.211297\tvalid_1's rmse: 0.212425\n",
      "[500]\ttraining's rmse: 0.211066\tvalid_1's rmse: 0.212371\n",
      "[600]\ttraining's rmse: 0.210883\tvalid_1's rmse: 0.212352\n",
      "[700]\ttraining's rmse: 0.21072\tvalid_1's rmse: 0.212343\n",
      "[800]\ttraining's rmse: 0.210579\tvalid_1's rmse: 0.21234\n",
      "[900]\ttraining's rmse: 0.210443\tvalid_1's rmse: 0.212336\n",
      "[1000]\ttraining's rmse: 0.210307\tvalid_1's rmse: 0.212329\n",
      "[1100]\ttraining's rmse: 0.21018\tvalid_1's rmse: 0.212326\n",
      "[1200]\ttraining's rmse: 0.210049\tvalid_1's rmse: 0.212325\n",
      "[1300]\ttraining's rmse: 0.209924\tvalid_1's rmse: 0.212323\n",
      "[1400]\ttraining's rmse: 0.209802\tvalid_1's rmse: 0.21232\n",
      "[1500]\ttraining's rmse: 0.209681\tvalid_1's rmse: 0.212317\n",
      "Early stopping, best iteration is:\n",
      "[1502]\ttraining's rmse: 0.209679\tvalid_1's rmse: 0.212317\n",
      "CPU times: user 25min 33s, sys: 16.2 s, total: 25min 50s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "clf = LGBMRegressor(n_estimators=n_estimators, \n",
    "                    max_depth=-1, \n",
    "                    feature_fraction= 0.4,\n",
    "                    num_leaves=32, \n",
    "                    learning_rate=.01)#, device='gpu')\n",
    "clf.fit(train_X, train_y, early_stopping_rounds=80, \n",
    "        eval_set=eval_set, eval_metric='rmse', verbose=100, \n",
    "        categorical_feature=categories)\n",
    "# [1435]\ttraining's rmse: 0.20979\tvalid_1's rmse: 0.212398\n",
    "# [1502]\ttraining's rmse: 0.209679\tvalid_1's rmse: 0.212317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6212, 'param_1'),\n",
       " (3399, 'param_2'),\n",
       " (2797, 'region'),\n",
       " (1852, 'category_name'),\n",
       " (1463, 'lgb14_preds'),\n",
       " (1048, 'difference_rnn_preds__rnn27_preds'),\n",
       " (1015, 'avg'),\n",
       " (935, 'rnn27_preds'),\n",
       " (921, 'mlp_preds'),\n",
       " (841, 'rnn12_preds'),\n",
       " (815, 'difference_rnn_preds__rnn12_preds'),\n",
       " (769, 'difference_lgb31_preds__lgb14_preds'),\n",
       " (763, 'min'),\n",
       " (745, 'difference_lgb11D_preds__lgb14_preds'),\n",
       " (742, 'difference_lgb10_preds__lgb14_preds'),\n",
       " (705, 'difference_lgb14_preds__lgb02A_preds'),\n",
       " (627, 'lgb11D_preds'),\n",
       " (591, 'difference_mlp_preds__lgb31_preds'),\n",
       " (569, 'difference_lgb09_preds__lgb02A_preds'),\n",
       " (557, 'difference_rnn_preds__lgb14_preds'),\n",
       " (548, 'difference_rnn27_preds__rnn12_preds'),\n",
       " (530, 'difference_rnn_preds__mlp_preds'),\n",
       " (528, 'difference_lgb31_preds__lgb09_preds'),\n",
       " (517, 'price'),\n",
       " (512, 'lgb11A_preds'),\n",
       " (510, 'difference_lgb31_preds__lgb02A_preds'),\n",
       " (496, 'difference_mlp_preds__lgb02A_preds'),\n",
       " (484, 'difference_lgb10_preds__lgb02A_preds'),\n",
       " (483, 'difference_mlp_preds__rnn12_preds'),\n",
       " (478, 'difference_mlp_preds__rnn27_preds'),\n",
       " (476, 'difference_lgb02A_preds__rnn12_preds'),\n",
       " (475, 'difference_lgb31_preds__rnn12_preds'),\n",
       " (474, 'difference_lgb11D_preds__lgb02A_preds'),\n",
       " (471, 'difference_lgb10_preds__lgb11D_preds'),\n",
       " (470, 'difference_lgb09_preds__lgb10_preds'),\n",
       " (459, 'difference_lgb31_preds__rnn27_preds'),\n",
       " (457, 'difference_mlp_preds__lgb10_preds'),\n",
       " (453, 'difference_lgb31_preds__lgb11D_preds'),\n",
       " (448, 'difference_lgb09_preds__lgb14_preds'),\n",
       " (443, 'difference_mlp_preds__lgb14_preds'),\n",
       " (431, 'difference_mlp_preds__lgb09_preds'),\n",
       " (407, 'difference_lgb10_preds__rnn27_preds'),\n",
       " (395, 'max'),\n",
       " (384, 'difference_rnn_preds__lgb11D_preds'),\n",
       " (380, 'difference_mlp_preds__lgb11D_preds'),\n",
       " (380, 'difference_lgb31_preds__lgb10_preds'),\n",
       " (378, 'difference_lgb09_preds__lgb11D_preds'),\n",
       " (369, 'difference_lgb02A_preds__rnn27_preds'),\n",
       " (364, 'difference_lgb14_preds__rnn12_preds'),\n",
       " (357, 'difference_lgb11D_preds__rnn12_preds'),\n",
       " (356, 'difference_lgb10_preds__rnn12_preds'),\n",
       " (354, 'rnn_preds'),\n",
       " (354, 'difference_rnn_preds__lgb31_preds'),\n",
       " (353, 'difference_lgb09_preds__rnn27_preds'),\n",
       " (347, 'difference_lgb11D_preds__rnn27_preds'),\n",
       " (338, 'difference_lgb14_preds__rnn27_preds'),\n",
       " (320, 'std'),\n",
       " (319, 'difference_lgb09_preds__rnn12_preds'),\n",
       " (315, 'lgb02A_preds'),\n",
       " (301, 'difference_rnn_preds__lgb02A_preds'),\n",
       " (299, 'lgb02_preds'),\n",
       " (297, 'lgb09_preds'),\n",
       " (295, 'difference_rnn_preds__lgb10_preds'),\n",
       " (289, 'lgb31_preds'),\n",
       " (288, 'lgb27_preds'),\n",
       " (286, 'difference_rnn_preds__lgb09_preds'),\n",
       " (271, 'lgb10_preds'),\n",
       " (257, 'parent_category_name')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(clf.feature_importances_, train_X.columns ),key=lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503424"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = 1502\n",
    "train_X = train_df[cols]\n",
    "train_y = y\n",
    "eval_set = [(train_X,train_y)]\n",
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219511\n",
      "[200]\ttraining's rmse: 0.213018\n",
      "[300]\ttraining's rmse: 0.211862\n",
      "[400]\ttraining's rmse: 0.211508\n",
      "[500]\ttraining's rmse: 0.211308\n",
      "[600]\ttraining's rmse: 0.211144\n",
      "[700]\ttraining's rmse: 0.211005\n",
      "[800]\ttraining's rmse: 0.210883\n",
      "[900]\ttraining's rmse: 0.210767\n",
      "[1000]\ttraining's rmse: 0.210656\n",
      "[1100]\ttraining's rmse: 0.21055\n",
      "[1200]\ttraining's rmse: 0.210439\n",
      "[1300]\ttraining's rmse: 0.210332\n",
      "[1400]\ttraining's rmse: 0.210226\n",
      "[1500]\ttraining's rmse: 0.210125\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1502]\ttraining's rmse: 0.210123\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219484\n",
      "[200]\ttraining's rmse: 0.213016\n",
      "[300]\ttraining's rmse: 0.211859\n",
      "[400]\ttraining's rmse: 0.211515\n",
      "[500]\ttraining's rmse: 0.211313\n",
      "[600]\ttraining's rmse: 0.211153\n",
      "[700]\ttraining's rmse: 0.211012\n",
      "[800]\ttraining's rmse: 0.210891\n",
      "[900]\ttraining's rmse: 0.210773\n",
      "[1000]\ttraining's rmse: 0.210662\n",
      "[1100]\ttraining's rmse: 0.210553\n",
      "[1200]\ttraining's rmse: 0.210446\n",
      "[1300]\ttraining's rmse: 0.21034\n",
      "[1400]\ttraining's rmse: 0.21024\n",
      "[1500]\ttraining's rmse: 0.210139\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1502]\ttraining's rmse: 0.210137\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219516\n",
      "[200]\ttraining's rmse: 0.213024\n",
      "[300]\ttraining's rmse: 0.211863\n",
      "[400]\ttraining's rmse: 0.211515\n",
      "[500]\ttraining's rmse: 0.211314\n",
      "[600]\ttraining's rmse: 0.211147\n",
      "[700]\ttraining's rmse: 0.211007\n",
      "[800]\ttraining's rmse: 0.210882\n",
      "[900]\ttraining's rmse: 0.210764\n",
      "[1000]\ttraining's rmse: 0.210652\n",
      "[1100]\ttraining's rmse: 0.210543\n",
      "[1200]\ttraining's rmse: 0.210439\n",
      "[1300]\ttraining's rmse: 0.210332\n",
      "[1400]\ttraining's rmse: 0.21023\n",
      "[1500]\ttraining's rmse: 0.210126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1502]\ttraining's rmse: 0.210124\n",
      "CPU times: user 1h 20min, sys: 38.3 s, total: 1h 20min 39s\n",
      "Wall time: 11min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_predls = []\n",
    "for i in range(3):\n",
    "    clf = LGBMRegressor(n_estimators=n_estimators, \n",
    "                    max_depth=-1, \n",
    "                    feature_fraction= 0.4,\n",
    "                    num_leaves=32, \n",
    "                    seed = i, \n",
    "                    learning_rate=.01)#, device='gpu')\n",
    "    clf.fit(train_X, train_y, early_stopping_rounds=80, \n",
    "        eval_set=eval_set, eval_metric='rmse', verbose=100, \n",
    "        categorical_feature=categories)\n",
    "    y_predls.append(clf.predict(test_df[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503424</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>0.437211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503425</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>0.151174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503426</th>\n",
       "      <td>8bab230b2ecd</td>\n",
       "      <td>0.124594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503427</th>\n",
       "      <td>8e348601fefc</td>\n",
       "      <td>0.102618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503428</th>\n",
       "      <td>8bd2fe400b89</td>\n",
       "      <td>0.167610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              item_id  deal_probability\n",
       "1503424  6544e41a8817          0.437211\n",
       "1503425  65b9484d670f          0.151174\n",
       "1503426  8bab230b2ecd          0.124594\n",
       "1503427  8e348601fefc          0.102618\n",
       "1503428  8bd2fe400b89          0.167610"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['deal_probability'] = sum(y_predls)/len(y_predls)\n",
    "test_df['deal_probability'] = np.clip(test_df['deal_probability'], .0001, .9999)\n",
    "test_df[['item_id', 'deal_probability']].to_csv('../lgbbsub_1606L2.csv.gz', compression='gzip', index=False, header=True)\n",
    "test_df[['item_id', 'deal_probability']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
